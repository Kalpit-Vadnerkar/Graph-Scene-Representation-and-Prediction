{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22fa957c-581f-4438-b7ab-710a26525c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147b0dde-1e79-4afd-93ba-033a31953598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(G):\n",
    "    node_features = []\n",
    "    for node, data in G.nodes(data=True):\n",
    "        features = [\n",
    "            data['x'], data['y'],\n",
    "            data['dynamic_object_exist_probability'],\n",
    "            data['dynamic_object_position_X'], data['dynamic_object_position_Y'],\n",
    "            data['dynamic_object_velocity_X'], data['dynamic_object_velocity_Y'],\n",
    "            data['nearest_traffic_light_detection_probability']\n",
    "        ]\n",
    "        node_features.append(features)\n",
    "    \n",
    "    edge_index = []\n",
    "    for edge in G.edges():\n",
    "        edge_index.append([edge[0], edge[1]])\n",
    "        #edge_index.append([edge[1], edge[0]])  # Add reverse edge for undirected graph\n",
    "    \n",
    "    # Convert to tensors and ensure node indices are zero-based\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Adjust node indices to be zero-based\n",
    "    node_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(G.nodes())}\n",
    "    edge_index = torch.tensor([[node_mapping[u], node_mapping[v]] for u, v in G.edges()], dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return x, edge_index\n",
    "\n",
    "def prepare_batch(batch_graphs, max_nodes):\n",
    "    x_seq, edge_index_seq = [], []\n",
    "    x_last, edge_index_last = [], []\n",
    "    y = []\n",
    "    batch_last = []\n",
    "    seq_lengths = []\n",
    "\n",
    "    total_nodes_last = 0\n",
    "    for batch_idx, graphs in enumerate(batch_graphs):\n",
    "        seq_x, seq_edge_index = [], []\n",
    "        for i, G in enumerate(graphs):\n",
    "            x, edge_index = preprocess_graph(G)\n",
    "\n",
    "            assert edge_index.max() < x.shape[0], f\"Edge index out of bounds for graph {i} in batch {batch_idx}\"\n",
    "\n",
    "            # Pad the graph with additional nodes if necessary\n",
    "            if x.shape[0] < max_nodes:\n",
    "                padding = torch.zeros((max_nodes - x.shape[0], x.shape[1]))\n",
    "                x = torch.cat([x, padding], dim=0)\n",
    "\n",
    "            if i < 3:\n",
    "                seq_x.append(x)\n",
    "                seq_edge_index.append(edge_index)\n",
    "            else:  # Last graph\n",
    "                x_last.append(x)\n",
    "                edge_index_last.append(edge_index + total_nodes_last)\n",
    "                y.append(x[:, 2:])  # Target features\n",
    "                batch_last.extend([batch_idx] * x.shape[0])  # Add batch index for each node\n",
    "                total_nodes_last += x.shape[0]\n",
    "\n",
    "        x_seq.append(seq_x)\n",
    "        edge_index_seq.append(seq_edge_index)\n",
    "        seq_lengths.append(len(seq_x))\n",
    "\n",
    "    # Pad x_seq\n",
    "    padded_x_seq = []\n",
    "    for batch in zip(*x_seq):\n",
    "        padded_batch = pad_sequence(batch, batch_first=True)\n",
    "        padded_x_seq.append(padded_batch)\n",
    "\n",
    "    padded_x_seq = torch.stack(padded_x_seq, dim=1)  # [batch_size, seq_len, max_nodes, features]\n",
    "\n",
    "    # Process edge_index_seq\n",
    "    max_edges = max(edge_index.shape[1] for batch in edge_index_seq for edge_index in batch)  # Maximum number of edges in the batch\n",
    "    processed_edge_index_seq = []\n",
    "    for batch in edge_index_seq:\n",
    "        batch_edge_index = []\n",
    "        for edge_index in batch:\n",
    "            # Pad edge_index if necessary\n",
    "            if edge_index.shape[1] < max_edges:\n",
    "                padding = torch.zeros((2, max_edges - edge_index.shape[1]), dtype=edge_index.dtype)\n",
    "                edge_index = torch.cat([edge_index, padding], dim=1)\n",
    "            batch_edge_index.append(edge_index)\n",
    "        processed_edge_index_seq.append(torch.stack(batch_edge_index))\n",
    "\n",
    "    edge_index_seq = torch.stack(processed_edge_index_seq)\n",
    "\n",
    "    # Concatenate all x_last and edge_index_last\n",
    "    x_last = torch.cat(x_last, dim=0)\n",
    "    edge_index_last = torch.cat(edge_index_last, dim=1)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    batch_last = torch.tensor(batch_last, dtype=torch.long)\n",
    "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
    "\n",
    "    assert edge_index_last.max() < x_last.shape[0], \"Edge index out of bounds in last graph\"\n",
    "\n",
    "    return padded_x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths\n",
    "\n",
    "def load_sequence_data(input_folder, batch_size=32):\n",
    "    all_sequences = []\n",
    "    max_nodes = 0\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        #print(f\"Processing file: {file_name}\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            sequences = pickle.load(f)\n",
    "\n",
    "            # Check if the sequences list is not empty\n",
    "            if sequences:\n",
    "                all_sequences.extend(sequences)\n",
    "\n",
    "                # Update the maximum number of nodes\n",
    "                max_nodes = max(max_nodes, max(G.number_of_nodes() for graphs in sequences for G in graphs))\n",
    "                #print(f\"Max number of nodes: {max_nodes}\")\n",
    "\n",
    "    # Shuffle the sequences\n",
    "    np.random.shuffle(all_sequences)\n",
    "\n",
    "    def batch_generator():\n",
    "        for i in range(0, len(all_sequences), batch_size):\n",
    "            batch = all_sequences[i:i+batch_size]\n",
    "\n",
    "            # Process the graphs in the batch\n",
    "            processed_batch = []\n",
    "            for graphs in batch:\n",
    "                processed_graphs = []\n",
    "                for G in graphs:\n",
    "                    processed_graphs.append(G)  # Append the graph object instead of the tuple\n",
    "                processed_batch.append(processed_graphs)\n",
    "\n",
    "            yield processed_batch\n",
    "\n",
    "    #print(f\"Max number of nodes: {max_nodes}\")\n",
    "    max_nodes = 300\n",
    "    return batch_generator(), max_nodes\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        return F.relu(self.conv(x, edge_index))\n",
    "\n",
    "class GraphSequenceNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSequenceNN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths = data\n",
    "        \n",
    "        batch_size, seq_len, max_nodes, _ = x_seq.size()\n",
    "        \n",
    "        gcn_out_seq = []\n",
    "        for i in range(seq_len):\n",
    "            x = x_seq[:, i]\n",
    "            edge_index = edge_index_seq[:, i]\n",
    "            \n",
    "            out = self.gcn1(x.reshape(-1, x.size(-1)), edge_index.reshape(2, -1))\n",
    "            out = self.gcn2(out, edge_index.reshape(2, -1))\n",
    "            \n",
    "            # Global mean pooling\n",
    "            out = global_mean_pool(out, torch.arange(batch_size).repeat_interleave(max_nodes).to(out.device))\n",
    "            gcn_out_seq.append(out)\n",
    "        \n",
    "        gcn_out_seq = torch.stack(gcn_out_seq, dim=1)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # RNN layer\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(gcn_out_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        rnn_out, _ = self.rnn(packed_input)\n",
    "        rnn_out, _ = nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        \n",
    "        # Process last graph\n",
    "        out_last = self.gcn1(x_last, edge_index_last)\n",
    "        out_last = self.gcn2(out_last, edge_index_last)\n",
    "        \n",
    "        # Combine RNN output with last graph features\n",
    "        batch_indices = torch.arange(batch_size).to(x_last.device).repeat_interleave(torch.bincount(batch_last))\n",
    "        rnn_out_last = rnn_out[batch_indices, -1]\n",
    "        combined = out_last + rnn_out_last\n",
    "        \n",
    "        # Final prediction for each node in the last graph\n",
    "        pred = self.fc(combined)\n",
    "        return pred\n",
    "\n",
    "\n",
    "\n",
    "def masked_mse_loss(pred, target, mask_threshold=0.5):\n",
    "    # Extract existence probability\n",
    "    exist_prob = target[:, 0]\n",
    "    \n",
    "    # Create mask based on existence probability\n",
    "    mask = (exist_prob >= mask_threshold).float()\n",
    "    \n",
    "    # Compute MSE loss\n",
    "    mse_loss = F.mse_loss(pred, target, reduction='none')\n",
    "    \n",
    "    # Apply mask to position and velocity losses (indices 1-4)\n",
    "    # Keep probability errors (indices 0 and 5) always included\n",
    "    masked_loss = torch.cat([\n",
    "        mse_loss[:, 0].unsqueeze(1),  # Existence probability loss (always included)\n",
    "        mse_loss[:, 1:5] * mask.unsqueeze(1),  # Position and velocity losses (masked)\n",
    "        mse_loss[:, 5].unsqueeze(1)  # Traffic light detection probability (always included)\n",
    "    ], dim=1)\n",
    "    \n",
    "    # Calculate mean loss\n",
    "    mean_loss = masked_loss.mean()\n",
    "    \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79b5d82b-99b0-4759-8fa6-0908ef2e3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_folder = \"Training Dataset/Sequence_Dataset\"\n",
    "test_input_folder = \"Testing Dataset/Sequence_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec75304d-2a72-42a5-828f-e3542ca747ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.7128, Test Loss: 0.0655\n",
      "Epoch 2/100, Train Loss: 0.7998, Test Loss: 0.0491\n",
      "Epoch 3/100, Train Loss: 0.6048, Test Loss: 0.0427\n",
      "Epoch 4/100, Train Loss: 0.5203, Test Loss: 0.0369\n",
      "Epoch 5/100, Train Loss: 0.4604, Test Loss: 0.0323\n",
      "Epoch 6/100, Train Loss: 0.4225, Test Loss: 0.0305\n",
      "Epoch 7/100, Train Loss: 0.4077, Test Loss: 0.0304\n",
      "Epoch 8/100, Train Loss: 0.3938, Test Loss: 0.0294\n",
      "Epoch 9/100, Train Loss: 0.3880, Test Loss: 0.0289\n",
      "Epoch 10/100, Train Loss: 0.3813, Test Loss: 0.0289\n",
      "Epoch 11/100, Train Loss: 0.3778, Test Loss: 0.0286\n",
      "Epoch 12/100, Train Loss: 0.3721, Test Loss: 0.0280\n",
      "Epoch 13/100, Train Loss: 0.3678, Test Loss: 0.0282\n",
      "Epoch 14/100, Train Loss: 0.3727, Test Loss: 0.0276\n",
      "Epoch 15/100, Train Loss: 0.3663, Test Loss: 0.0286\n",
      "Epoch 16/100, Train Loss: 0.3608, Test Loss: 0.0274\n",
      "Epoch 17/100, Train Loss: 0.3585, Test Loss: 0.0275\n",
      "Epoch 18/100, Train Loss: 0.3554, Test Loss: 0.0269\n",
      "Epoch 19/100, Train Loss: 0.3525, Test Loss: 0.0273\n",
      "Epoch 20/100, Train Loss: 0.3509, Test Loss: 0.0269\n",
      "Epoch 21/100, Train Loss: 0.3485, Test Loss: 0.0265\n",
      "Epoch 22/100, Train Loss: 0.3462, Test Loss: 0.0262\n",
      "Epoch 23/100, Train Loss: 0.3416, Test Loss: 0.0258\n",
      "Epoch 24/100, Train Loss: 0.3382, Test Loss: 0.0263\n",
      "Epoch 25/100, Train Loss: 0.3360, Test Loss: 0.0255\n",
      "Epoch 26/100, Train Loss: 0.3327, Test Loss: 0.0251\n",
      "Epoch 27/100, Train Loss: 0.3261, Test Loss: 0.0250\n",
      "Epoch 28/100, Train Loss: 0.3241, Test Loss: 0.0244\n",
      "Epoch 29/100, Train Loss: 0.3213, Test Loss: 0.0241\n",
      "Epoch 30/100, Train Loss: 0.3163, Test Loss: 0.0240\n",
      "Epoch 31/100, Train Loss: 0.3122, Test Loss: 0.0240\n",
      "Epoch 32/100, Train Loss: 0.3105, Test Loss: 0.0232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m batch_generator, max_nodes \u001b[38;5;241m=\u001b[39m load_sequence_data(train_input_folder, batch_size)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_generator:\n\u001b[0;32m---> 41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[22], line 39\u001b[0m, in \u001b[0;36mprepare_batch\u001b[0;34m(batch_graphs, max_nodes)\u001b[0m\n\u001b[1;32m     37\u001b[0m seq_x, seq_edge_index \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, G \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graphs):\n\u001b[0;32m---> 39\u001b[0m     x, edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdge index out of bounds for graph \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Pad the graph with additional nodes if necessary\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36mpreprocess_graph\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m     15\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39mappend([edge[\u001b[38;5;241m0\u001b[39m], edge[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#edge_index.append([edge[1], edge[0]])  # Add reverse edge for undirected graph\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Convert to tensors and ensure node indices are zero-based\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(edge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Adjust node indices to be zero-based\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 8\n",
    "hidden_dim = 128\n",
    "output_dim = 6\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Model and optimizer\n",
    "model = GraphSequenceNN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize empty lists to store loss values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "def evaluate_model(model, test_input_folder, batch_size, max_nodes, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    test_batch_generator, _ = load_sequence_data(test_input_folder, batch_size)\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_batch_generator:\n",
    "            test_data = prepare_batch(test_batch, max_nodes)\n",
    "            x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths = [t.to(device) for t in test_data]\n",
    "            output = model((x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths))\n",
    "            loss = masked_mse_loss(output, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "# Training and evaluation loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    batch_generator, max_nodes = load_sequence_data(train_input_folder, batch_size)\n",
    "    for batch in batch_generator:\n",
    "        data = prepare_batch(batch, max_nodes)\n",
    "        x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths = [t.to(device) for t in data]\n",
    "        optimizer.zero_grad()\n",
    "        output = model((x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths))\n",
    "        loss = masked_mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    # Evaluation on test data\n",
    "    total_test_loss = evaluate_model(model, test_input_folder, batch_size, max_nodes, device)\n",
    "    \n",
    "    # Append the losses of this epoch to the lists\n",
    "    train_loss_values.append(total_train_loss)\n",
    "    test_loss_values.append(total_test_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {total_train_loss:.4f}, Test Loss: {total_test_loss:.4f}\")\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_loss_values, 'r', label='Training loss')\n",
    "plt.plot(test_loss_values, 'b', label='Test loss')\n",
    "plt.legend()\n",
    "plt.title('Loss values')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Final evaluation on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch_generator, _ = load_sequence_data(test_input_folder, batch_size)\n",
    "    for test_batch in test_batch_generator:\n",
    "        test_data = prepare_batch(test_batch, max_nodes)\n",
    "        x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths = [t.to(device) for t in test_data]\n",
    "        predictions = model((x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths))\n",
    "        # Process predictions as needed\n",
    "        print(\"Test Predictions:\", predictions)\n",
    "        print(\"Actual Values:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8331a0c-23ad-41fc-971a-20c054a9fa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
