{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22fa957c-581f-4438-b7ab-710a26525c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "147b0dde-1e79-4afd-93ba-033a31953598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(G):\n",
    "    node_features = []\n",
    "    for _, data in G.nodes(data=True):\n",
    "        features = [\n",
    "            data['x'], data['y'],\n",
    "            data['dynamic_object_exist_probability'],\n",
    "            data['dynamic_object_position_X'], data['dynamic_object_position_Y'],\n",
    "            data['dynamic_object_velocity_X'], data['dynamic_object_velocity_Y'],\n",
    "            data['nearest_traffic_light_detection_probability']\n",
    "        ]\n",
    "        node_features.append(features)\n",
    "    \n",
    "    edge_index = []\n",
    "    for edge in G.edges():\n",
    "        edge_index.append([edge[0], edge[1]])\n",
    "        edge_index.append([edge[1], edge[0]])  # Add reverse edge for undirected graph\n",
    "    \n",
    "    return torch.tensor(node_features, dtype=torch.float), torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "def prepare_batch(batch_graphs, max_nodes):\n",
    "    x_seq, edge_index_seq = [], []\n",
    "    x_last, edge_index_last = [], []\n",
    "    y = []\n",
    "    batch_last = []\n",
    "    seq_lengths = []\n",
    "\n",
    "    for batch_idx, graphs in enumerate(batch_graphs):\n",
    "        seq_x, seq_edge_index = [], []\n",
    "        for i, G in enumerate(graphs):\n",
    "            x, edge_index = preprocess_graph(G)\n",
    "\n",
    "            # Pad the graph with additional nodes if necessary\n",
    "            if x.shape[0] < max_nodes:\n",
    "                padding = torch.zeros((max_nodes - x.shape[0], x.shape[1]))\n",
    "                x = torch.cat([x, padding], dim=0)\n",
    "\n",
    "            if i < 3:\n",
    "                seq_x.append(x)\n",
    "                seq_edge_index.append(edge_index)\n",
    "            else:  # Last graph\n",
    "                x_last.append(x)\n",
    "                edge_index_last.append(edge_index + len(torch.cat(x_last)))\n",
    "                y.append(x[:, 2:])  # Target features\n",
    "                batch_last.extend([batch_idx] * x.shape[0])  # Add batch index for each node\n",
    "\n",
    "        x_seq.append(seq_x)\n",
    "        edge_index_seq.append(seq_edge_index)\n",
    "        seq_lengths.append(len(seq_x))\n",
    "\n",
    "    # Pad x_seq\n",
    "    padded_x_seq = []\n",
    "    for batch in zip(*x_seq):\n",
    "        padded_batch = pad_sequence(batch, batch_first=True)\n",
    "        padded_x_seq.append(padded_batch)\n",
    "\n",
    "    padded_x_seq = torch.stack(padded_x_seq, dim=1)  # [batch_size, seq_len, max_nodes, features]\n",
    "\n",
    "    # Process edge_index_seq\n",
    "    max_edges = max(edge_index.shape[1] for batch in edge_index_seq for edge_index in batch)  # Maximum number of edges in the batch\n",
    "    processed_edge_index_seq = []\n",
    "    for batch in edge_index_seq:\n",
    "        batch_edge_index = []\n",
    "        for edge_index in batch:\n",
    "            # Pad edge_index if necessary\n",
    "            if edge_index.shape[1] < max_edges:\n",
    "                padding = torch.zeros((2, max_edges - edge_index.shape[1]), dtype=edge_index.dtype)\n",
    "                edge_index = torch.cat([edge_index, padding], dim=1)\n",
    "            batch_edge_index.append(edge_index)\n",
    "        processed_edge_index_seq.append(torch.stack(batch_edge_index))\n",
    "\n",
    "    edge_index_seq = torch.stack(processed_edge_index_seq)\n",
    "\n",
    "    # Concatenate all x_last and edge_index_last\n",
    "    x_last = torch.cat(x_last, dim=0)\n",
    "    edge_index_last = torch.cat(edge_index_last, dim=1)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    batch_last = torch.tensor(batch_last, dtype=torch.long)\n",
    "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
    "\n",
    "    return padded_x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths\n",
    "\n",
    "def load_sequence_data(input_folder, batch_size=32):\n",
    "    all_sequences = []\n",
    "    max_nodes = 0\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            sequences = pickle.load(f)\n",
    "\n",
    "            # Check if the sequences list is not empty\n",
    "            if sequences:\n",
    "                all_sequences.extend(sequences)\n",
    "\n",
    "                # Update the maximum number of nodes\n",
    "                max_nodes = max(max_nodes, max(G.number_of_nodes() for graphs in sequences for G in graphs))\n",
    "                print(f\"Max number of nodes: {max_nodes}\")\n",
    "\n",
    "    # Shuffle the sequences\n",
    "    np.random.shuffle(all_sequences)\n",
    "\n",
    "    def batch_generator():\n",
    "        for i in range(0, len(all_sequences), batch_size):\n",
    "            batch = all_sequences[i:i+batch_size]\n",
    "\n",
    "            # Process the graphs in the batch\n",
    "            processed_batch = []\n",
    "            for graphs in batch:\n",
    "                processed_graphs = []\n",
    "                for G in graphs:\n",
    "                    processed_graphs.append(G)  # Append the graph object instead of the tuple\n",
    "                processed_batch.append(processed_graphs)\n",
    "\n",
    "            yield processed_batch\n",
    "\n",
    "    return batch_generator(), max_nodes\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        return F.relu(self.conv(x, edge_index))\n",
    "\n",
    "class GraphSequenceNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSequenceNN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths = data\n",
    "        \n",
    "        batch_size, seq_len, max_nodes, _ = x_seq.size()\n",
    "        \n",
    "        gcn_out_seq = []\n",
    "        for i in range(seq_len):\n",
    "            x = x_seq[:, i]\n",
    "            edge_index = edge_index_seq[:, i]\n",
    "            \n",
    "            out = self.gcn1(x.reshape(-1, x.size(-1)), edge_index.reshape(2, -1))\n",
    "            out = self.gcn2(out, edge_index.reshape(2, -1))\n",
    "            \n",
    "            # Global mean pooling\n",
    "            out = global_mean_pool(out, torch.arange(batch_size).repeat_interleave(max_nodes).to(out.device))\n",
    "            gcn_out_seq.append(out)\n",
    "        \n",
    "        gcn_out_seq = torch.stack(gcn_out_seq, dim=1)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # RNN layer\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(gcn_out_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, h_n = self.rnn(packed_input)\n",
    "        \n",
    "        # Process last graph\n",
    "        out_last = self.gcn1(x_last, edge_index_last)\n",
    "        out_last = self.gcn2(out_last, edge_index_last)\n",
    "        \n",
    "        # Global mean pooling for last graph\n",
    "        out_last = global_mean_pool(out_last, batch_last)\n",
    "        \n",
    "        # Combine RNN output with last graph output\n",
    "        combined = h_n.squeeze(0) + out_last\n",
    "        \n",
    "        # Final prediction\n",
    "        pred = self.fc(combined)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79b5d82b-99b0-4759-8fa6-0908ef2e3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"Sequence_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec75304d-2a72-42a5-828f-e3542ca747ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Cleaned_Sequence_1.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_10.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_11.pkl\n",
      "Processing file: Cleaned_Sequence_12.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_13.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_14.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_15.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_2.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_3.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_4.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_5.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_6.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_7.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_8.pkl\n",
      "Max number of nodes: 874\n",
      "Processing file: Cleaned_Sequence_9.pkl\n",
      "Max number of nodes: 874\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 27970 is out of bounds for dimension 0 with size 27968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_last\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_last\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_last\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lengths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 159\u001b[0m, in \u001b[0;36mGraphSequenceNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    156\u001b[0m _, h_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(packed_input)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Process last graph\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m out_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_last\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m out_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(out_last, edge_index_last)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Global mean pooling for last graph\u001b[39;00m\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 125\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:108\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m--> 108\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    110\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/home/da0698@unt.ad.unt.edu/anaconda3/envs/dlgpu/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 27970 is out of bounds for dimension 0 with size 27968"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 8  # Number of node features\n",
    "hidden_dim = 64\n",
    "output_dim = 6  # Number of output features\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = GraphSequenceNN(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_generator, max_nodes = load_sequence_data(input_folder, batch_size)\n",
    "    \n",
    "    for batch in batch_generator:\n",
    "        data = prepare_batch(batch, max_nodes)\n",
    "        x_seq, edge_index_seq, x_last, edge_index_last, y, batch_last, seq_lengths = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model((x_seq, edge_index_seq, x_last, edge_index_last, batch_last, seq_lengths))\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# After training, you can use the model for predictions\n",
    "model.eval()\n",
    "#with torch.no_grad():\n",
    "    # Prepare your test data\n",
    "#    test_batch_generator, _ = load_sequence_data(test_input_folder, batch_size)\n",
    "#    for test_batch in test_batch_generator:\n",
    "#        test_data = prepare_batch(test_batch, max_nodes)\n",
    "#        predictions = model(test_data)\n",
    "        # Process predictions as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b4b87-ae1d-426c-9ae6-603bc59dfa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65c4df-0b75-46fb-899c-8865f0b0269a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
